import torch
import numpy as np
from PIL import Image
import math

class DapaoBatchImageGrid:
    """
    ğŸ­æ‰¹æ¬¡å›¾ç»„åˆ@ç‚®è€å¸ˆçš„å°è¯¾å ‚
    
    åŠŸèƒ½ï¼š
    - å°†è¾“å…¥çš„å›¾åƒæ‰¹æ¬¡æŒ‰ç½‘æ ¼æ’åˆ—ç»„åˆæˆä¸€å¼ å¤§å›¾
    - æ”¯æŒçµæ´»çš„è¡Œåˆ—è®¾ç½®ï¼ˆä¼˜å…ˆåˆ—æ•°ï¼Œå¯æŒ‡å®šè¡Œæ•°ï¼‰
    - æ”¯æŒå•å›¾å°ºå¯¸è‡ªå®šä¹‰ï¼ˆ0ä¸ºåŸå›¾å°ºå¯¸ï¼‰
    - æ”¯æŒé—´è·ï¼ˆGapï¼‰è®¾ç½®
    - æ”¯æŒå¤šç§è£å‰ª/ç¼©æ”¾æ¨¡å¼
    - æ”¯æŒèƒŒæ™¯é¢œè‰²è®¾ç½®
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "ğŸ–¼ï¸ å›¾åƒæ‰¹æ¬¡": ("IMAGE", {"tooltip": "è¾“å…¥çš„å›¾åƒæ‰¹æ¬¡"}),
                "ğŸ“Š åˆ—æ•°": ("INT", {
                    "default": 3, 
                    "min": 0, 
                    "max": 100, 
                    "step": 1, 
                    "tooltip": "ç½‘æ ¼åˆ—æ•°ã€‚è®¾ç½®>0æ—¶ä¼˜å…ˆç”Ÿæ•ˆï¼›è®¾ç½®ä¸º0æ—¶ä½¿ç”¨è¡Œæ•°è®¡ç®—"
                }),
                "ğŸ§± è¡Œæ•°": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 100, 
                    "step": 1, 
                    "tooltip": "ç½‘æ ¼è¡Œæ•°ã€‚å½“åˆ—æ•°ä¸º0æ—¶ç”Ÿæ•ˆï¼ˆè‡ªåŠ¨ç®—åˆ—æ•°ï¼‰ï¼›å½“åˆ—æ•°>0æ—¶ï¼Œä½œä¸ºæœ€å°è¡Œæ•°ï¼ˆä¸å¤Ÿç•™ç™½ï¼‰"
                }),
                "â†”ï¸ å•å›¾å®½åº¦": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 8192, 
                    "step": 1, 
                    "tooltip": "å•å¼ å°å›¾å®½åº¦ã€‚0è¡¨ç¤ºä½¿ç”¨åŸå›¾å®½åº¦"
                }),
                "â†•ï¸ å•å›¾é«˜åº¦": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 8192, 
                    "step": 1, 
                    "tooltip": "å•å¼ å°å›¾é«˜åº¦ã€‚0è¡¨ç¤ºä½¿ç”¨åŸå›¾é«˜åº¦"
                }),
                "ğŸ“ é—´è·": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 512, 
                    "step": 1, 
                    "tooltip": "å°å›¾ä¹‹é—´çš„é—´è·ï¼ˆåƒç´ ï¼‰"
                }),
                "âœ‚ï¸ è£å‰ªæ¨¡å¼": (["åŸæ¯”ä¾‹", "æ‹‰ä¼¸", "å±…ä¸­è£å‰ª", "é¡¶éƒ¨è£å‰ª", "åº•éƒ¨è£å‰ª", "å·¦ä¾§è£å‰ª", "å³ä¾§è£å‰ª"], {
                    "default": "åŸæ¯”ä¾‹",
                    "tooltip": "å½“åŸå›¾ä¸ç›®æ ‡å°ºå¯¸æ¯”ä¾‹ä¸ä¸€è‡´æ—¶çš„å¤„ç†æ–¹å¼"
                }),
                "ğŸ¨ èƒŒæ™¯ç±»å‹": (["é€æ˜", "è‡ªå®šä¹‰é¢œè‰²"], {
                    "default": "é€æ˜",
                    "tooltip": "èƒŒæ™¯å¡«å……ç±»å‹"
                }),
                "ğŸ¨ èƒŒæ™¯é¢œè‰²": ("STRING", {
                    "default": "#FFFFFF", 
                    "tooltip": "èƒŒæ™¯é¢œè‰²ï¼ˆHexæ ¼å¼ï¼Œå¦‚#FFFFFFï¼‰ï¼Œä»…åœ¨è‡ªå®šä¹‰é¢œè‰²æ¨¡å¼ä¸‹ç”Ÿæ•ˆ"
                }),
                "ğŸ“ é™åˆ¶æœ€é•¿è¾¹": ("INT", {
                    "default": 0, 
                    "min": 0, 
                    "max": 16384, 
                    "step": 64, 
                    "tooltip": "è¾“å‡ºå›¾åƒé™åˆ¶æœ€é•¿è¾¹ï¼ˆåƒç´ ï¼‰ï¼Œ0ä¸ºä¸é™åˆ¶"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("ğŸ–¼ï¸ æ‹¼æ¥å›¾åƒ",)
    FUNCTION = "create_grid"
    CATEGORY = "ğŸ¤–Dapao-Toolbox"

    def create_grid(self, **kwargs):
        # 1. è§£æè¾“å…¥
        images = kwargs["ğŸ–¼ï¸ å›¾åƒæ‰¹æ¬¡"]
        columns = kwargs["ğŸ“Š åˆ—æ•°"]
        rows = kwargs["ğŸ§± è¡Œæ•°"]
        width = kwargs["â†”ï¸ å•å›¾å®½åº¦"]
        height = kwargs["â†•ï¸ å•å›¾é«˜åº¦"]
        gap = kwargs["ğŸ“ é—´è·"]
        crop_mode = kwargs["âœ‚ï¸ è£å‰ªæ¨¡å¼"]
        bg_type = kwargs["ğŸ¨ èƒŒæ™¯ç±»å‹"]
        bg_color = kwargs["ğŸ¨ èƒŒæ™¯é¢œè‰²"]
        max_side = kwargs["ğŸ“ é™åˆ¶æœ€é•¿è¾¹"]

        if images is None or len(images) == 0:
            raise ValueError("âŒ é”™è¯¯ï¼šè¾“å…¥å›¾åƒæ‰¹æ¬¡ä¸ºç©º")
            
        batch_size, img_h, img_w, _ = images.shape
        
        # 2. ç¡®å®šç›®æ ‡å°ºå¯¸
        target_w = width if width > 0 else img_w
        target_h = height if height > 0 else img_h
        
        # 3. è®¡ç®—è¡Œåˆ—å¸ƒå±€
        if columns > 0:
            cols = columns
            # å¦‚æœæŒ‡å®šäº†rowsï¼Œå–è¾ƒå¤§å€¼ä»¥ç¡®ä¿å¸ƒå±€ï¼ˆå¯èƒ½æ˜¯ç•™ç™½ï¼‰
            # ä½†å¿…é¡»è‡³å°‘èƒ½å®¹çº³æ‰€æœ‰å›¾ç‰‡ï¼šbatch_size
            needed_rows = math.ceil(batch_size / cols)
            final_rows = max(rows, needed_rows) if rows > 0 else needed_rows
        elif rows > 0:
            final_rows = rows
            cols = math.ceil(batch_size / final_rows)
        else:
            # é»˜è®¤ 3åˆ—
            cols = 3
            final_rows = math.ceil(batch_size / cols)
            
        # 4. å‡†å¤‡ç”»å¸ƒ
        # å®½åº¦ = åˆ—æ•° * å•å›¾å®½ + (åˆ—æ•° - 1) * é—´è·
        # é«˜åº¦ = è¡Œæ•° * å•å›¾é«˜ + (è¡Œæ•° - 1) * é—´è·
        # è€ƒè™‘åˆ°è¾¹ç¼˜å¯èƒ½ä¹Ÿéœ€è¦é—´è·ï¼Ÿé€šå¸¸ Grid ä¸åŒ…å«å¤–è¾¹æ¡†é—´è·ï¼ŒåªåŒ…å«å…ƒç´ é—´è·ã€‚è¿™é‡ŒæŒ‰å…ƒç´ é—´è·å¤„ç†ã€‚
        
        canvas_w = cols * target_w + (cols - 1) * gap
        canvas_h = final_rows * target_h + (final_rows - 1) * gap
        
        # é¿å… gap å¯¼è‡´è´Ÿæ•°ï¼ˆå½“ cols=0 æˆ– 1 æ—¶ gap ç³»æ•°ä¸º 0ï¼‰
        canvas_w = max(canvas_w, 1)
        canvas_h = max(canvas_h, 1)

        # è§£æèƒŒæ™¯è‰²
        if bg_type == "é€æ˜":
            color = (0, 0, 0, 0)
            mode = "RGBA"
        else:
            try:
                c = bg_color.lstrip('#')
                rgb = tuple(int(c[i:i+2], 16) for i in (0, 2, 4))
                color = rgb + (255,)
                mode = "RGBA"
            except:
                color = (255, 255, 255, 255)
                mode = "RGBA"

        canvas = Image.new(mode, (canvas_w, canvas_h), color)
        
        # 5. é€å¼ å¤„ç†å¹¶ç²˜è´´
        for idx, img_tensor in enumerate(images):
            # è¶…è¿‡ç½‘æ ¼å®¹é‡çš„å›¾ç‰‡å°†è¢«å¿½ç•¥ï¼ˆå¦‚æœ rows é™åˆ¶äº†æ€»æ•°ä¸” cols ä¹Ÿå›ºå®š... ä½†ä¸Šé¢çš„é€»è¾‘ needed_rows ä¿è¯äº†èƒ½è£…ä¸‹ï¼‰
            # é™¤é columns=0, rows>0 ä¸” batch_size > rows*cols? 
            # æ¯”å¦‚ rows=2, batch=5 -> cols=3 -> 2*3=6 > 5. OK.
            
            # è®¡ç®—å½“å‰è¡Œåˆ—
            r = idx // cols
            c = idx % cols
            
            # å¦‚æœè¶…å‡ºè®¡ç®—å‡ºçš„è¡Œæ•°ï¼ˆç†è®ºä¸Šä¸ä¼šï¼Œé™¤éé€»è¾‘æœ‰è¯¯ï¼‰ï¼Œè·³è¿‡
            if r >= final_rows:
                break
                
            # Tensor -> PIL
            i = 255. * img_tensor.cpu().numpy()
            img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
            
            # å¤„ç†å•å›¾ (ç¼©æ”¾/è£å‰ª)
            processed_img = self.process_image(img, target_w, target_h, crop_mode)
            
            # ç¡®ä¿æ˜¯ RGBA ä»¥æ”¯æŒé€æ˜èƒŒæ™¯åˆæˆ
            if processed_img.mode != "RGBA":
                processed_img = processed_img.convert("RGBA")
                
            # è®¡ç®—åæ ‡
            x = c * (target_w + gap)
            y = r * (target_h + gap)
            
            # ç²˜è´´ (ä½¿ç”¨ alpha composite)
            canvas.paste(processed_img, (x, y), processed_img)
            
        # 6. é™åˆ¶æœ€å¤§è¾¹
        if max_side > 0:
            w, h = canvas.size
            if w > max_side or h > max_side:
                ratio = min(max_side / w, max_side / h)
                new_w = int(w * ratio)
                new_h = int(h * ratio)
                canvas = canvas.resize((new_w, new_h), Image.Resampling.LANCZOS)
                
        # 7. è¾“å‡º
        # PIL -> Tensor
        img_np = np.array(canvas).astype(np.float32) / 255.0
        output = torch.from_numpy(img_np).unsqueeze(0) # [1, H, W, C]
        
        return (output,)

    def process_image(self, img, target_w, target_h, mode):
        # å¦‚æœå°ºå¯¸å®Œå…¨ä¸€è‡´ï¼Œç›´æ¥è¿”å›
        if img.size == (target_w, target_h):
            return img
            
        if mode == "æ‹‰ä¼¸":
            return img.resize((target_w, target_h), Image.Resampling.LANCZOS)
            
        img_w, img_h = img.size
        
        if mode == "åŸæ¯”ä¾‹":
            # ç¼©æ”¾ä»¥é€‚åº”ç›®æ ‡æ¡† (Aspect Fit)
            scale = min(target_w / img_w, target_h / img_h)
            new_w = int(img_w * scale)
            new_h = int(img_h * scale)
            resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            
            # åˆ›å»ºé€æ˜åº•
            res = Image.new("RGBA", (target_w, target_h), (0, 0, 0, 0))
            # å±…ä¸­ç²˜è´´
            x = (target_w - new_w) // 2
            y = (target_h - new_h) // 2
            res.paste(resized, (x, y))
            return res
            
        # è£å‰ªæ¨¡å¼ (Aspect Fill + Crop)
        # å…ˆç¼©æ”¾åˆ°è¦†ç›–ç›®æ ‡åŒºåŸŸ
        scale = max(target_w / img_w, target_h / img_h)
        new_w = int(img_w * scale)
        new_h = int(img_h * scale)
        resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
        
        left, top = 0, 0
        if new_w > target_w:
            if mode in ["å±…ä¸­è£å‰ª", "é¡¶éƒ¨è£å‰ª", "åº•éƒ¨è£å‰ª"]:
                left = (new_w - target_w) // 2
            elif mode == "å³ä¾§è£å‰ª":
                left = new_w - target_w
            # å·¦ä¾§è£å‰ª left=0
            
        if new_h > target_h:
            if mode in ["å±…ä¸­è£å‰ª", "å·¦ä¾§è£å‰ª", "å³ä¾§è£å‰ª"]:
                top = (new_h - target_h) // 2
            elif mode == "åº•éƒ¨è£å‰ª":
                top = new_h - target_h
            # é¡¶éƒ¨è£å‰ª top=0
            
        return resized.crop((left, top, left + target_w, top + target_h))
