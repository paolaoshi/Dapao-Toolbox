import torch
import numpy as np
from PIL import Image, ImageDraw
import math

class ImageGridStitcherV2Node:
    """
    å›¾ç‰‡ç½‘æ ¼æ‹¼æ¥ V2 - è§£å†³ç¼“å­˜é—®é¢˜çš„å…¨æ–°ç‰ˆæœ¬
    
    åŠŸèƒ½è¯´æ˜ï¼š
    - æ¥æ”¶å›¾åƒæ‰¹æ¬¡
    - æŒ‰æŒ‡å®šè¡Œåˆ—æ•°æ’åˆ—
    - å¼ºåˆ¶ç»Ÿä¸€æ¯å¼ å°å›¾çš„å®½é«˜
    - æ”¯æŒå¤šç§è£å‰ªæ¨¡å¼ï¼ˆå«åŸæ¯”ä¾‹ï¼‰
    - æ”¯æŒè‡ªå®šä¹‰èƒŒæ™¯ï¼ˆé€æ˜æˆ–é¢œè‰²ï¼‰
    - æ”¯æŒé™åˆ¶è¾“å‡ºæ€»å°ºå¯¸
    """
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        return float("NaN")
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                # ğŸ–¼ï¸ å›¾åƒæ‰¹æ¬¡
                "ğŸ–¼ï¸ å›¾åƒæ‰¹æ¬¡": ("IMAGE", {
                    "tooltip": "è¾“å…¥çš„å›¾åƒæ‰¹æ¬¡ï¼ŒåŒ…å«å¤šå¼ éœ€è¦æ‹¼æ¥çš„å›¾ç‰‡"
                }),
                # ğŸ“Š åˆ—æ•°
                "ğŸ“Š åˆ—æ•°": ("INT", {
                    "default": 3,
                    "min": 1,
                    "max": 100,
                    "step": 1,
                    "tooltip": "ç½‘æ ¼çš„åˆ—æ•°ï¼Œè¡Œæ•°å°†æ ¹æ®å›¾ç‰‡æ•°é‡è‡ªåŠ¨è®¡ç®—"
                }),
                # â†”ï¸ å•å›¾å®½åº¦
                "â†”ï¸ å•å›¾å®½åº¦": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 4096,
                    "step": 8,
                    "tooltip": "æ¯å¼ å°å›¾åœ¨ç½‘æ ¼ä¸­çš„å¼ºåˆ¶å®½åº¦"
                }),
                # â†•ï¸ å•å›¾é«˜åº¦
                "â†•ï¸ å•å›¾é«˜åº¦": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 4096,
                    "step": 8,
                    "tooltip": "æ¯å¼ å°å›¾åœ¨ç½‘æ ¼ä¸­çš„å¼ºåˆ¶é«˜åº¦"
                }),
                # âœ‚ï¸ è£å‰ªæ¨¡å¼
                "âœ‚ï¸ è£å‰ªæ¨¡å¼": (["åŸæ¯”ä¾‹", "æ‹‰ä¼¸", "å±…ä¸­è£å‰ª", "é¡¶éƒ¨è£å‰ª", "åº•éƒ¨è£å‰ª", "å·¦ä¾§è£å‰ª", "å³ä¾§è£å‰ª"], {
                    "default": "åŸæ¯”ä¾‹",
                    "tooltip": "å½“åŸå›¾æ¯”ä¾‹ä¸ç›®æ ‡å®½é«˜ä¸ä¸€è‡´æ—¶çš„å¤„ç†æ–¹å¼"
                }),
                # ğŸ¨ èƒŒæ™¯ç±»å‹
                "ğŸ¨ èƒŒæ™¯ç±»å‹": (["é€æ˜", "è‡ªå®šä¹‰é¢œè‰²"], {
                    "default": "é€æ˜",
                    "tooltip": "æ‹¼æ¥èƒŒæ™¯çš„å¡«å……æ–¹å¼"
                }),
                # ğŸ¨ èƒŒæ™¯é¢œè‰²
                "ğŸ¨ èƒŒæ™¯é¢œè‰²": ("STRING", {
                    "default": "#FFFFFF",
                    "multiline": False,
                    "tooltip": "è‡ªå®šä¹‰èƒŒæ™¯é¢œè‰²ï¼ˆHexæ ¼å¼ï¼Œå¦‚#FFFFFFï¼‰ï¼Œä»…åœ¨èƒŒæ™¯ç±»å‹ä¸º'è‡ªå®šä¹‰é¢œè‰²'æ—¶ç”Ÿæ•ˆ"
                }),
                # ğŸ“ é™åˆ¶æœ€é•¿è¾¹
                "ğŸ“ é™åˆ¶æœ€é•¿è¾¹": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 16384,
                    "step": 64,
                    "tooltip": "é™åˆ¶è¾“å‡ºå¤§å›¾çš„æœ€é•¿è¾¹åƒç´ ï¼Œ0è¡¨ç¤ºä¸é™åˆ¶"
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("ğŸ–¼ï¸ æ‹¼æ¥å›¾åƒ",)
    FUNCTION = "stitch_images"
    CATEGORY = "ğŸ¤–Dapao-Toolbox"
    
    def stitch_images(self, **kwargs):
        # 1. è·å–è¾“å…¥å‚æ•°
        images = kwargs["ğŸ–¼ï¸ å›¾åƒæ‰¹æ¬¡"]
        columns = kwargs["ğŸ“Š åˆ—æ•°"]
        cell_w = kwargs["â†”ï¸ å•å›¾å®½åº¦"]
        cell_h = kwargs["â†•ï¸ å•å›¾é«˜åº¦"]
        crop_mode = kwargs["âœ‚ï¸ è£å‰ªæ¨¡å¼"]
        bg_type = kwargs["ğŸ¨ èƒŒæ™¯ç±»å‹"]
        bg_color_hex = kwargs["ğŸ¨ èƒŒæ™¯é¢œè‰²"]
        max_side = kwargs["ğŸ“ é™åˆ¶æœ€é•¿è¾¹"]
        
        # 2. è®¡ç®—ç½‘æ ¼è¡Œåˆ—
        batch_size = images.shape[0]
        if batch_size == 0:
            raise ValueError("âŒ é”™è¯¯: è¾“å…¥çš„å›¾åƒæ‰¹æ¬¡ä¸ºç©ºï¼")
            
        rows = math.ceil(batch_size / columns)
        
        # 3. å‡†å¤‡ç”»å¸ƒ
        canvas_w = columns * cell_w
        canvas_h = rows * cell_h
        
        # è§£æèƒŒæ™¯é¢œè‰²
        if bg_type == "é€æ˜":
            bg_color = (0, 0, 0, 0)
            mode = "RGBA"
        else:
            # è§£æHexé¢œè‰²
            try:
                c = bg_color_hex.lstrip('#')
                rgb = tuple(int(c[i:i+2], 16) for i in (0, 2, 4))
                bg_color = rgb + (255,) # æ·»åŠ Alphaé€šé“ä¸ºä¸é€æ˜
                mode = "RGBA"
            except:
                print(f"Warning: Invalid color code {bg_color_hex}, defaulting to black.")
                bg_color = (0, 0, 0, 255)
                mode = "RGBA"
        
        canvas = Image.new(mode, (canvas_w, canvas_h), bg_color)
        
        # 4. å¤„ç†æ¯ä¸€å¼ å›¾ç‰‡
        for idx, img_tensor in enumerate(images):
            # tensor (H, W, C) -> PIL
            # è¾“å…¥tensorèŒƒå›´æ˜¯0-1ï¼Œéœ€è¦ä¹˜ä»¥255
            i = 255. * img_tensor.cpu().numpy()
            img = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
            
            # å¤„ç†å°ºå¯¸å’Œè£å‰ª
            processed_img = self.process_single_image(img, cell_w, cell_h, crop_mode)
            
            # è®¡ç®—ä½ç½®
            col = idx % columns
            row = idx // columns
            x = col * cell_w
            y = row * cell_h
            
            # ç²˜è´´åˆ°ç”»å¸ƒ
            if processed_img.mode != 'RGBA':
                processed_img = processed_img.convert('RGBA')
                
            # ä¿®æ­£ç²˜è´´é€»è¾‘ï¼šæ€»æ˜¯ä½¿ç”¨alphaæ··åˆ
            canvas.paste(processed_img, (x, y), processed_img)

        # 5. æ•´ä½“ç¼©æ”¾
        if max_side > 0:
            w, h = canvas.size
            if w > max_side or h > max_side:
                ratio = min(max_side / w, max_side / h)
                new_w = int(w * ratio)
                new_h = int(h * ratio)
                canvas = canvas.resize((new_w, new_h), Image.LANCZOS)

        # 6. è½¬å› Tensor
        img_np = np.array(canvas).astype(np.float32) / 255.0
        output = torch.from_numpy(img_np).unsqueeze(0) # (1, H, W, C)
        
        return (output,)

    def process_single_image(self, img, target_w, target_h, mode):
        """å¤„ç†å•å¼ å›¾ç‰‡çš„ç¼©æ”¾å’Œè£å‰ª"""
        if mode == "æ‹‰ä¼¸":
            return img.resize((target_w, target_h), Image.Resampling.LANCZOS)
        
        # åŸæ¯”ä¾‹æ¨¡å¼ (Aspect Fit)
        if mode == "åŸæ¯”ä¾‹":
            img_w, img_h = img.size
            
            # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œå–è¾ƒå°å€¼ä»¥ä¿è¯å›¾ç‰‡å®Œæ•´æ”¾å…¥
            scale_w = target_w / img_w
            scale_h = target_h / img_h
            scale = min(scale_w, scale_h)
            
            new_w = int(img_w * scale)
            new_h = int(img_h * scale)
            
            # ç¼©æ”¾å›¾ç‰‡
            resized_img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            
            # åˆ›å»ºé€æ˜åº•å›¾
            final_img = Image.new("RGBA", (target_w, target_h), (0, 0, 0, 0))
            
            # è®¡ç®—å±…ä¸­ä½ç½®
            paste_x = (target_w - new_w) // 2
            paste_y = (target_h - new_h) // 2
            
            # ç²˜è´´å›¾ç‰‡ï¼ˆä¿æŒé€æ˜åº¦ï¼‰
            final_img.paste(resized_img, (paste_x, paste_y))
            
            return final_img
        
        # è£å‰ªæ¨¡å¼
        img_w, img_h = img.size
        
        # 1. ç­‰æ¯”ç¼©æ”¾åˆ°è¦†ç›–ç›®æ ‡åŒºåŸŸ
        scale_w = target_w / img_w
        scale_h = target_h / img_h
        scale = max(scale_w, scale_h) # å–å¤§å€¼ä»¥è¦†ç›–
        
        new_w = int(img_w * scale)
        new_h = int(img_h * scale)
        
        resized_img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
        
        # 2. è®¡ç®—è£å‰ªåæ ‡
        left = 0
        top = 0
        
        # å®½åº¦è¶…å‡ºæˆ–ç›¸ç­‰
        if new_w > target_w:
            if mode == "å±…ä¸­è£å‰ª" or mode == "é¡¶éƒ¨è£å‰ª" or mode == "åº•éƒ¨è£å‰ª":
                left = (new_w - target_w) // 2
            elif mode == "å·¦ä¾§è£å‰ª":
                left = 0
            elif mode == "å³ä¾§è£å‰ª":
                left = new_w - target_w
        
        # é«˜åº¦è¶…å‡ºæˆ–ç›¸ç­‰
        if new_h > target_h:
            if mode == "å±…ä¸­è£å‰ª" or mode == "å·¦ä¾§è£å‰ª" or mode == "å³ä¾§è£å‰ª":
                top = (new_h - target_h) // 2
            elif mode == "é¡¶éƒ¨è£å‰ª":
                top = 0
            elif mode == "åº•éƒ¨è£å‰ª":
                top = new_h - target_h
                
        right = left + target_w
        bottom = top + target_h
        
        return resized_img.crop((left, top, right, bottom))
