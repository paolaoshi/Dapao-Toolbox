import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont

class DapaoImageRatioLimitNode:
    """
    å›¾åƒæ¯”å°ºå¯¸é™å®šèŠ‚ç‚¹
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        # ç”Ÿæˆ 0.1 åˆ° 2.5 çš„ç™¾ä¸‡åƒç´ é€‰é¡¹ï¼Œæ­¥é•¿ 0.1
        megapixel_options = [f"{i/10:.1f}" for i in range(1, 26)]
        
        return {
            "required": {
                "ğŸ”¢ ç™¾ä¸‡åƒç´ ": (megapixel_options, {"default": "1.0", "tooltip": "ç›®æ ‡å›¾åƒçš„æ€»åƒç´ æ•°ï¼ˆç™¾ä¸‡çº§ï¼‰"}),
                "ğŸ“ å®½é«˜æ¯”": ([
                    "1:1 (æ­£æ–¹å½¢)",
                    "2:3 (ç»å…¸ç«–å±)", "3:4 (é»„é‡‘æ¯”ä¾‹ç«–)", "3:5 (ä¼˜é›…ç«–å±)", "4:5 (è‰ºæœ¯ç”»æ¡†ç«–)", "5:7 (æ ‡å‡†ç«–å±)", "5:8 (é«˜è€¸ç«–å±)",
                    "7:9 (ç°ä»£ç«–å±)", "9:16 (æ‰‹æœºç«–å±)", "9:19 (é«˜ç˜¦ç«–å±)", "9:21 (è¶…é«˜ç«–å±)", "9:32 (æ‘©å¤©å¤§æ¥¼)",
                    "3:2 (ç»å…¸æ¨ªå±)", "4:3 (é»„é‡‘æ¯”ä¾‹æ¨ª)", "5:3 (å®½è§†é‡)", "5:4 (å¹³è¡¡ç”»æ¡†æ¨ª)", "7:5 (ä¼˜é›…æ¨ªå±)", "8:5 (ç”µå½±è§†è§’)",
                    "9:7 (è‰ºæœ¯æ¨ªå±)", "16:9 (ç”µè„‘å±å¹•)", "19:9 (ç”µå½±è¶…å®½)", "21:9 (å²è¯—è¶…å®½)", "32:9 (æé™è¶…å®½)"
                ], {"default": "1:1 (æ­£æ–¹å½¢)", "tooltip": "é¢„è®¾çš„å®½é«˜æ¯”"}),
                "ğŸ”¢ æ•´é™¤å€æ•°": (["8", "16", "32", "64"], {"default": "64", "tooltip": "å®½é«˜æ•°å€¼å¿…é¡»èƒ½è¢«æ­¤æ•°æ•´é™¤"}),
                "ğŸ”˜ å¯ç”¨è‡ªå®šä¹‰æ¯”ä¾‹": ("BOOLEAN", {"default": False, "label_on": "å¯ç”¨", "label_off": "ç¦ç”¨", "tooltip": "æ˜¯å¦ä½¿ç”¨ä¸‹æ–¹è‡ªå®šä¹‰å®½é«˜æ¯”"}),
            },
            "optional": {
                "âœï¸ è‡ªå®šä¹‰å®½é«˜æ¯”": ("STRING", {"default": "1:1", "tooltip": "æ ¼å¼å¦‚ 16:9"}),
            }
        }

    RETURN_TYPES = ("INT", "INT", "STRING", "IMAGE")
    RETURN_NAMES = ("â†”ï¸ å®½åº¦", "â†•ï¸ é«˜åº¦", "ğŸ“ åˆ†è¾¨ç‡ä¿¡æ¯", "ğŸ–¼ï¸ é¢„è§ˆå›¾")
    FUNCTION = "calculate_dimensions"
    CATEGORY = "ğŸ¤–Dapao-Toolbox"
    OUTPUT_NODE = True

    def create_preview_image(self, width, height, resolution, ratio_display):
        # 1024x1024 é¢„è§ˆç”»å¸ƒ
        preview_size = (1024, 1024)
        image = Image.new('RGB', preview_size, (0, 0, 0))  # é»‘è‰²èƒŒæ™¯
        draw = ImageDraw.Draw(image)

        # ç»˜åˆ¶æ·±ç°è‰²ç½‘æ ¼
        grid_color = '#333333'
        grid_spacing = 50
        for x in range(0, preview_size[0], grid_spacing):
            draw.line([(x, 0), (x, preview_size[1])], fill=grid_color)
        for y in range(0, preview_size[1], grid_spacing):
            draw.line([(0, y), (preview_size[0], y)], fill=grid_color)

        # è®¡ç®—é¢„è§ˆæ¡†å°ºå¯¸ï¼ˆæœ€å¤§800åƒç´ ï¼‰
        preview_width = 800
        preview_height = int(preview_width * (height / width))
        
        # å¦‚æœé«˜åº¦è¿‡é«˜ï¼Œåˆ™ä»¥é«˜åº¦ä¸ºåŸºå‡†
        if preview_height > 800:
            preview_height = 800
            preview_width = int(preview_height * (width / height))

        # è®¡ç®—å±…ä¸­ä½ç½®
        x_offset = (preview_size[0] - preview_width) // 2
        y_offset = (preview_size[1] - preview_height) // 2

        # ç»˜åˆ¶çº¢æ¡†
        draw.rectangle(
            [(x_offset, y_offset), (x_offset + preview_width, y_offset + preview_height)],
            outline='red',
            width=4
        )

        # ç»˜åˆ¶æ–‡æœ¬
        try:
            # è®¡ç®—æ–‡æœ¬ä½ç½®
            text_y = y_offset + preview_height // 2
            
            # åˆ†è¾¨ç‡æ–‡æœ¬ (çº¢è‰²)
            font_size_large = 48
            font_size_medium = 36
            font_size_small = 32
            
            # å°è¯•åŠ è½½é»˜è®¤å­—ä½“ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å­—ä½“å¯¹è±¡
            try:
                font_large = ImageFont.truetype("arial.ttf", font_size_large)
                font_medium = ImageFont.truetype("arial.ttf", font_size_medium)
                font_small = ImageFont.truetype("arial.ttf", font_size_small)
            except:
                font_large = ImageFont.load_default()
                font_medium = ImageFont.load_default()
                font_small = ImageFont.load_default()

            draw.text((preview_size[0]//2, text_y), 
                     f"{width}x{height}", 
                     fill='red', 
                     anchor="mm",
                     font=font_large)
            
            # æ¯”ä¾‹æ–‡æœ¬ (çº¢è‰²)
            draw.text((preview_size[0]//2, text_y + 60),
                     f"({ratio_display})",
                     fill='red',
                     anchor="mm",
                     font=font_medium)
            
            # åº•éƒ¨ä¿¡æ¯æ–‡æœ¬ (ç™½è‰²)
            draw.text((preview_size[0]//2, y_offset + preview_height + 60),
                     f"Resolution: {resolution}",
                     fill='white',
                     anchor="mm",
                     font=font_small)
            
        except Exception as e:
            print(f"DapaoImageRatioLimitNode: Error drawing text - {e}")

        # è½¬æ¢ä¸º Tensor
        return self.pil2tensor(image)

    def calculate_dimensions(self, **kwargs):
        # è·å–å‚æ•°
        megapixel = float(kwargs.get("ğŸ”¢ ç™¾ä¸‡åƒç´ ", "1.0"))
        aspect_ratio_str = kwargs.get("ğŸ“ å®½é«˜æ¯”", "1:1 (æ­£æ–¹å½¢)")
        divisible_by = int(kwargs.get("ğŸ”¢ æ•´é™¤å€æ•°", "64"))
        use_custom = kwargs.get("ğŸ”˜ å¯ç”¨è‡ªå®šä¹‰æ¯”ä¾‹", False)
        custom_ratio_str = kwargs.get("âœï¸ è‡ªå®šä¹‰å®½é«˜æ¯”", "1:1")

        if use_custom and custom_ratio_str:
            numeric_ratio = custom_ratio_str
            ratio_display = custom_ratio_str
        else:
            numeric_ratio = aspect_ratio_str.split(' ')[0]
            ratio_display = numeric_ratio
        
        try:
            width_ratio, height_ratio = map(int, numeric_ratio.split(':'))
        except ValueError:
            # å®¹é”™å¤„ç†ï¼šå¦‚æœæ ¼å¼é”™è¯¯ï¼Œé»˜è®¤ 1:1
            width_ratio, height_ratio = 1, 1
            print(f"DapaoImageRatioLimitNode: Invalid ratio format '{numeric_ratio}', using 1:1")
        
        total_pixels = megapixel * 1_000_000
        dimension = (total_pixels / (width_ratio * height_ratio)) ** 0.5
        width = int(dimension * width_ratio)
        height = int(dimension * height_ratio)

        # åº”ç”¨æ•´é™¤å€æ•°
        width = round(width / divisible_by) * divisible_by
        height = round(height / divisible_by) * divisible_by
        
        # é˜²æ­¢ 0 å°ºå¯¸
        width = max(divisible_by, width)
        height = max(divisible_by, height)

        resolution = f"{width} x {height}"
        
        # ç”Ÿæˆé¢„è§ˆå›¾
        preview = self.create_preview_image(width, height, resolution, ratio_display)
        
        return (width, height, resolution, preview)

    def pil2tensor(self, image):
        return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)
