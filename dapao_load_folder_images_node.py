import os
import torch
import numpy as np
from PIL import Image, ImageOps

class DapaoLoadFolderImages:
    """
    ğŸ¦æ–‡ä»¶å¤¹åŠ è½½å›¾åƒ@ç‚®è€å¸ˆçš„å°è¯¾å ‚
    
    åŠŸèƒ½ï¼š
    - ä»æŒ‡å®šæ–‡ä»¶å¤¹åŠ è½½å›¾ç‰‡åºåˆ—
    - æ”¯æŒæ’åºã€æ•°é‡é™åˆ¶ã€èµ·å§‹ç´¢å¼•
    - æ™ºèƒ½æ‰¹æ¬¡å°ºå¯¸ç»Ÿä¸€ï¼ˆæ”¯æŒæŒ‰é¦–å›¾æˆ–æŒ‡å®šå°ºå¯¸ï¼‰
    - æ”¯æŒé™åˆ¶æœ€é•¿è¾¹ï¼ˆä¼˜åŒ–æ˜¾å­˜ï¼‰
    - çµæ´»çš„é€‚é…æ¨¡å¼ï¼ˆè£å‰ª/å¡«å……/æ‹‰ä¼¸ï¼‰
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "ğŸ“‚ æ–‡ä»¶å¤¹è·¯å¾„": ("STRING", {"default": "", "multiline": False, "tooltip": "å›¾ç‰‡æ‰€åœ¨çš„æ–‡ä»¶å¤¹è·¯å¾„"}),
                "ğŸ”¢ åŠ è½½æ•°é‡": ("INT", {"default": 0, "min": 0, "max": 10000, "step": 1, "tooltip": "é™åˆ¶åŠ è½½å›¾ç‰‡çš„æ•°é‡ï¼Œ0è¡¨ç¤ºåŠ è½½æ‰€æœ‰"}),
                "ğŸ èµ·å§‹ç´¢å¼•": ("INT", {"default": 0, "min": 0, "max": 10000, "step": 1, "tooltip": "è·³è¿‡å‰Nå¼ å›¾ç‰‡"}),
                "ğŸ”„ æ’åºæ–¹å¼": (["æ–‡ä»¶åå‡åº (A-Z)", "æ–‡ä»¶åé™åº (Z-A)", "æ—¥æœŸ (æœ€æ–°åœ¨å‰)", "æ—¥æœŸ (æœ€æ—§åœ¨å‰)", "éšæœº"], {"default": "æ–‡ä»¶åå‡åº (A-Z)"}),
                "ğŸ“ ç»Ÿä¸€å°ºå¯¸è§„åˆ™": (["ç»Ÿä¸€ä¸ºé¦–å›¾å°ºå¯¸", "æŒ‡å®šå›ºå®šå°ºå¯¸"], {"default": "ç»Ÿä¸€ä¸ºé¦–å›¾å°ºå¯¸"}),
                "â†”ï¸ æŒ‡å®šå®½åº¦": ("INT", {"default": 512, "min": 64, "max": 8192, "step": 8, "tooltip": "ä»…åœ¨é€‰æ‹©'æŒ‡å®šå›ºå®šå°ºå¯¸'æ—¶ç”Ÿæ•ˆ"}),
                "â†•ï¸ æŒ‡å®šé«˜åº¦": ("INT", {"default": 512, "min": 64, "max": 8192, "step": 8, "tooltip": "ä»…åœ¨é€‰æ‹©'æŒ‡å®šå›ºå®šå°ºå¯¸'æ—¶ç”Ÿæ•ˆ"}),
                "ğŸ“ é™åˆ¶æœ€é•¿è¾¹": ("INT", {"default": 0, "min": 0, "max": 16384, "step": 64, "tooltip": "é¢„å¤„ç†ï¼šå°†å›¾ç‰‡æœ€é•¿è¾¹é™åˆ¶åœ¨æŒ‡å®šåƒç´ å†…ï¼ˆ0ä¸é™åˆ¶ï¼‰ã€‚å¯¹'ç»Ÿä¸€ä¸ºé¦–å›¾å°ºå¯¸'æ¨¡å¼æœ‰æ•ˆï¼Œå¯å‡å°æ˜¾å­˜å ç”¨"}),
                "ğŸ› ï¸ é€‚é…æ¨¡å¼": (["ä¿æŒæ¯”ä¾‹-å¡«å……é»‘è¾¹", "ä¿æŒæ¯”ä¾‹-å±…ä¸­è£å‰ª", "æ‹‰ä¼¸"], {"default": "ä¿æŒæ¯”ä¾‹-å¡«å……é»‘è¾¹", "tooltip": "å½“å›¾ç‰‡å°ºå¯¸ä¸ç›®æ ‡æ‰¹æ¬¡å°ºå¯¸ä¸ä¸€è‡´æ—¶çš„å¤„ç†æ–¹å¼"}),
                "ğŸ¨ å¡«å……é¢œè‰²": ("STRING", {"default": "#000000", "tooltip": "å¡«å……é»‘è¾¹æ—¶çš„èƒŒæ™¯é¢œè‰²ï¼ˆHexæ ¼å¼ï¼‰"}),
            }
        }

    RETURN_TYPES = ("IMAGE", "INT", "STRING")
    RETURN_NAMES = ("ğŸ–¼ï¸ å›¾åƒæ‰¹æ¬¡", "ğŸ”¢ æ•°é‡", "ğŸ“‚ æ–‡ä»¶ååˆ—è¡¨")
    FUNCTION = "load_images"
    CATEGORY = "ğŸ¤–Dapao-Toolbox"

    def load_images(self, **kwargs):
        folder_path = kwargs["ğŸ“‚ æ–‡ä»¶å¤¹è·¯å¾„"]
        cap = kwargs["ğŸ”¢ åŠ è½½æ•°é‡"]
        start_index = kwargs["ğŸ èµ·å§‹ç´¢å¼•"]
        sort_method = kwargs["ğŸ”„ æ’åºæ–¹å¼"]
        size_rule = kwargs["ğŸ“ ç»Ÿä¸€å°ºå¯¸è§„åˆ™"]
        fixed_w = kwargs["â†”ï¸ æŒ‡å®šå®½åº¦"]
        fixed_h = kwargs["â†•ï¸ æŒ‡å®šé«˜åº¦"]
        limit_max_side = kwargs["ğŸ“ é™åˆ¶æœ€é•¿è¾¹"]
        fit_mode = kwargs["ğŸ› ï¸ é€‚é…æ¨¡å¼"]
        pad_color_hex = kwargs["ğŸ¨ å¡«å……é¢œè‰²"]

        # 1. éªŒè¯è·¯å¾„
        if not os.path.isdir(folder_path):
            # å°è¯•å»æ‰å¯èƒ½å­˜åœ¨çš„å¼•å·
            folder_path = folder_path.strip('"').strip("'")
            if not os.path.isdir(folder_path):
                raise ValueError(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶å¤¹è·¯å¾„ä¸å­˜åœ¨ -> {folder_path}")

        # 2. è·å–æ–‡ä»¶åˆ—è¡¨
        valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.webp', '.tiff', '.gif'}
        files = []
        for f in os.listdir(folder_path):
            ext = os.path.splitext(f)[1].lower()
            if ext in valid_extensions:
                files.append(os.path.join(folder_path, f))
        
        if not files:
            raise ValueError("âŒ é”™è¯¯ï¼šæ–‡ä»¶å¤¹å†…æœªæ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶")

        # 3. æ’åº
        if sort_method == "æ–‡ä»¶åå‡åº (A-Z)":
            files.sort()
        elif sort_method == "æ–‡ä»¶åé™åº (Z-A)":
            files.sort(reverse=True)
        elif sort_method == "æ—¥æœŸ (æœ€æ–°åœ¨å‰)":
            files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        elif sort_method == "æ—¥æœŸ (æœ€æ—§åœ¨å‰)":
            files.sort(key=lambda x: os.path.getmtime(x))
        elif sort_method == "éšæœº":
            import random
            random.shuffle(files)

        # 4. æˆªå–èŒƒå›´
        if start_index > 0:
            files = files[start_index:]
        if cap > 0:
            files = files[:cap]
            
        if not files:
            print("âš ï¸ è­¦å‘Šï¼šç»è¿‡ç­›é€‰åæ²¡æœ‰å›¾ç‰‡å¯åŠ è½½")
            # è¿”å›ä¸€ä¸ªç©ºçš„ 1x1 é»‘è‰²å›¾åƒä»¥é˜²æŠ¥é”™
            empty = torch.zeros((1, 1, 1, 3), dtype=torch.float32)
            return (empty, 0, [])

        # 5. ç¡®å®šç›®æ ‡å°ºå¯¸
        target_w, target_h = 0, 0
        
        if size_rule == "æŒ‡å®šå›ºå®šå°ºå¯¸":
            target_w, target_h = fixed_w, fixed_h
        else:
            # è¯»å–ç¬¬ä¸€å¼ å›¾ä½œä¸ºåŸºå‡†
            try:
                first_img = Image.open(files[0])
                w, h = first_img.size
                
                # å¦‚æœæœ‰æœ€é•¿è¾¹é™åˆ¶ï¼Œå…ˆåº”ç”¨åˆ°åŸºå‡†å°ºå¯¸
                if limit_max_side > 0:
                    scale = min(1.0, limit_max_side / max(w, h))
                    if scale < 1.0:
                        w = int(w * scale)
                        h = int(h * scale)
                
                target_w, target_h = w, h
            except Exception as e:
                raise ValueError(f"âŒ è¯»å–é¦–å›¾å¤±è´¥: {e}")

        # è§£æå¡«å……é¢œè‰²
        try:
            c = pad_color_hex.lstrip('#')
            rgb = tuple(int(c[i:i+2], 16) for i in (0, 2, 4))
            pad_color = rgb
        except:
            pad_color = (0, 0, 0)

        # 6. é€ä¸ªå¤„ç†åŠ è½½
        image_list = []
        filename_list = []
        
        for file_path in files:
            try:
                img = Image.open(file_path)
                # è½¬æ¢é¢œè‰²ç©ºé—´
                img = ImageOps.exif_transpose(img) # å¤„ç†æ—‹è½¬ä¿¡æ¯
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # é¢„å¤„ç†ï¼šé™åˆ¶å•å›¾æœ€å¤§è¾¹ï¼ˆå¦‚æœæ˜¯ç»Ÿä¸€é¦–å›¾æ¨¡å¼ï¼Œè¿™ä¸€æ­¥æœ‰åŠ©äºå‡å°‘ä¸­é—´å†…å­˜ï¼›å¦‚æœæ˜¯å›ºå®šå°ºå¯¸ï¼Œç›´æ¥ç¼©æ”¾åˆ°å›ºå®šå°ºå¯¸æ›´ä¼˜ï¼Œä½†ä¸ºäº†é€»è¾‘ç»Ÿä¸€...ï¼‰
                # å…¶å®å¦‚æœ fit_mode æ˜¯æ‹‰ä¼¸æˆ–å¡«å……ï¼Œæˆ‘ä»¬æœ€ç»ˆéƒ½è¦ resize åˆ° target_w/hã€‚
                # è¿™é‡Œçš„ limit_max_side ä¸»è¦æ˜¯ä¸ºäº†é˜²æ­¢åŠ è½½å·¨å‹å›¾ç‰‡å¯¼è‡´å¤„ç†è¿‡ç¨‹å´©æ‰
                if limit_max_side > 0 and size_rule == "ç»Ÿä¸€ä¸ºé¦–å›¾å°ºå¯¸":
                     # åªæœ‰åœ¨éå›ºå®šå°ºå¯¸æ¨¡å¼ä¸‹ï¼Œå•ç‹¬é™åˆ¶æ‰æœ‰æ„ä¹‰ï¼Ÿ
                     # ä¸ï¼Œå¦‚æœç›®æ ‡å°±æ˜¯å›ºå®šå°ºå¯¸ï¼Œé‚£ç›´æ¥ç¼©æ”¾åˆ° target å³å¯ã€‚
                     # å¦‚æœæ˜¯ç»Ÿä¸€é¦–å›¾ï¼Œé¦–å›¾å·²ç»é™åˆ¶äº† targetã€‚
                     # é‚£ä¹ˆåç»­å›¾ç‰‡æ˜¯å¦éœ€è¦å…ˆ limit å† fit? 
                     # ç›´æ¥ Fit åˆ° Target å³å¯ã€‚
                     pass

                processed_img = self.process_image(img, target_w, target_h, fit_mode, pad_color)
                
                # è½¬ Tensor
                img_np = np.array(processed_img).astype(np.float32) / 255.0
                image_list.append(torch.from_numpy(img_np))
                filename_list.append(os.path.basename(file_path))
                
            except Exception as e:
                print(f"âš ï¸ è·³è¿‡æŸåæˆ–æ— æ³•è¯»å–çš„å›¾ç‰‡: {file_path} -> {e}")
                continue

        if not image_list:
             raise ValueError("âŒ é”™è¯¯ï¼šæ‰€æœ‰å›¾ç‰‡å¤„ç†å¤±è´¥")

        # å †å æ‰¹æ¬¡
        output_images = torch.stack(image_list, dim=0) # [B, H, W, C]
        
        return (output_images, len(image_list), filename_list)

    def process_image(self, img, target_w, target_h, mode, pad_color):
        if img.size == (target_w, target_h):
            return img
            
        if mode == "æ‹‰ä¼¸":
            return img.resize((target_w, target_h), Image.Resampling.LANCZOS)
            
        elif mode == "ä¿æŒæ¯”ä¾‹-å±…ä¸­è£å‰ª":
            # Aspect Fill
            img_w, img_h = img.size
            scale = max(target_w / img_w, target_h / img_h)
            new_w = int(img_w * scale)
            new_h = int(img_h * scale)
            resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            
            left = (new_w - target_w) // 2
            top = (new_h - target_h) // 2
            return resized.crop((left, top, left + target_w, top + target_h))
            
        else: # ä¿æŒæ¯”ä¾‹-å¡«å……é»‘è¾¹ (Aspect Fit)
            img_w, img_h = img.size
            scale = min(target_w / img_w, target_h / img_h)
            new_w = int(img_w * scale)
            new_h = int(img_h * scale)
            resized = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
            
            new_img = Image.new("RGB", (target_w, target_h), pad_color)
            left = (target_w - new_w) // 2
            top = (target_h - new_h) // 2
            new_img.paste(resized, (left, top))
            return new_img
