import torch
import numpy as np
import io
from PIL import Image

class DapaoImageCompressionNode:
    """
    ç”»è´¨æ— æŸå‹ç¼©èŠ‚ç‚¹
    æä¾›é«˜è´¨é‡çš„å›¾åƒå‹ç¼©åŠŸèƒ½ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {"tooltip": "è¾“å…¥å›¾åƒ"}),
                "quality": ("INT", {
                    "default": 90, 
                    "min": 1, 
                    "max": 100, 
                    "step": 1, 
                    "tooltip": "å‹ç¼©è´¨é‡ (1-100)ï¼Œæ•°å€¼è¶Šé«˜ç”»è´¨è¶Šå¥½ï¼Œå»ºè®®85-95"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("ğŸ–¼ï¸ å›¾åƒ",)
    FUNCTION = "compress_image"
    CATEGORY = "ğŸ¤–Dapao-Toolbox"

    def compress_image(self, image, quality):
        result_images = []
        
        # å¤„ç† batch
        for i in range(image.shape[0]):
            img_tensor = image[i]
            img_pil = self.tensor2pil(img_tensor)
            
            # å‹ç¼©å¤„ç†
            # ä½¿ç”¨ BytesIO åœ¨å†…å­˜ä¸­æ¨¡æ‹Ÿä¿å­˜ JPEG è¿‡ç¨‹
            buffer = io.BytesIO()
            
            # è½¬æ¢æ¨¡å¼ï¼Œç¡®ä¿å…¼å®¹æ€§
            if img_pil.mode == 'RGBA':
                # å¦‚æœéœ€è¦ä¿æŒé€æ˜åº¦ï¼ŒJPEGä¸æ”¯æŒRGBAï¼Œé€šå¸¸è½¬RGBæˆ–æ··åˆèƒŒæ™¯
                # è¿™é‡Œä¸ºäº†å‹ç¼©æ•ˆæœï¼Œå¦‚æœç”¨æˆ·æ„å›¾æ˜¯JPEGå‹ç¼©ï¼Œé€šå¸¸æ˜¯RGB
                # ä½†ä¸ºäº†é€šç”¨æ€§ï¼Œå¦‚æœåŸå›¾æ˜¯RGBAï¼Œæˆ‘ä»¬å…ˆå°è¯•è½¬RGBï¼ˆJPEGæ ‡å‡†ï¼‰
                # æˆ–è€…å¦‚æœç”¨æˆ·æƒ³ä¿ç•™é€æ˜åº¦ä½†å‹ç¼©ä½“ç§¯ï¼Œåº”è¯¥ç”¨PNGå‹ç¼©ï¼ˆWebPç­‰ï¼‰
                # æŒ‰ç…§å‚è€ƒç«å“é€»è¾‘ï¼ˆJPEGå‹ç¼©ï¼‰ï¼Œé€šå¸¸è½¬RGB
                img_pil = img_pil.convert('RGB')
            elif img_pil.mode != 'RGB':
                img_pil = img_pil.convert('RGB')
                
            # ä¿å­˜åˆ° bufferï¼Œåº”ç”¨å‹ç¼©å‚æ•°
            # optimize=True: å¯ç”¨ç¼–ç ä¼˜åŒ–
            # subsampling=0: å…³é—­è‰²åº¦äºŒæ¬¡é‡‡æ · (4:4:4)ï¼Œä¿æŒæœ€é«˜é¢œè‰²è´¨é‡
            img_pil.save(buffer, format="JPEG", quality=quality, optimize=True, subsampling=0)
            
            # ä» buffer é‡æ–°è¯»å–
            buffer.seek(0)
            compressed_img_pil = Image.open(buffer)
            
            # è½¬å› Tensor
            result_images.append(self.pil2tensor(compressed_img_pil))
            
        # åˆå¹¶ batch
        if len(result_images) > 1:
            return (torch.cat(result_images, dim=0),)
        else:
            return (result_images[0],)

    def tensor2pil(self, image):
        return Image.fromarray(np.clip(255. * image.cpu().numpy(), 0, 255).astype(np.uint8))

    def pil2tensor(self, image):
        return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)
